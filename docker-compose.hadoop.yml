version: '3.8'

services:
  namenode:
    image: hadoop-multi:latest
    container_name: namenode
    hostname: namenode
    ports:
      - "9870:9870"
      # - "9000:9000"
    environment:
      - CLUSTER_NAME=hadoop-cluster
      - NODE_TYPE=namenode
    volumes:
      - ./config/namenode:/home/hadoop/hadoop/etc/hadoop
      - namenode_data:/home/hadoop/hdfs/namenode
      - ./scripts:/home/hadoop/scripts
    networks:
      - spark-hadoop-network
    command: /home/hadoop/scripts/start-namenode.sh

  datanode1:
    image: hadoop-multi:latest
    container_name: datanode1
    hostname: datanode1
    depends_on:
      - namenode
    ports:
      - "9864:9864"
    environment:
      - NODE_TYPE=datanode
      - NAMENODE_HOST=namenode
    volumes:
      - ./config/datanode:/home/hadoop/hadoop/etc/hadoop
      - datanode1_data:/home/hadoop/hdfs/datanode
      - ./scripts:/home/hadoop/scripts
    networks:
      - spark-hadoop-network
    command: /home/hadoop/scripts/start-datanode.sh

  datanode2:
    image: hadoop-multi:latest
    container_name: datanode2
    hostname: datanode2
    depends_on:
      - namenode
    ports:
      - "9865:9864"
    environment:
      - NODE_TYPE=datanode
      - NAMENODE_HOST=namenode
    volumes:
      - ./config/datanode:/home/hadoop/hadoop/etc/hadoop
      - datanode2_data:/home/hadoop/hdfs/datanode
      - ./scripts:/home/hadoop/scripts
    networks:
      - spark-hadoop-network
    command: /home/hadoop/scripts/start-datanode.sh

  resourcemanager:
    image: hadoop-multi:latest
    container_name: resourcemanager
    hostname: resourcemanager
    depends_on:
      - namenode
    ports:
      - "8088:8088"
      - "8030:8030"
      - "8031:8031"
      - "8032:8032"
      - "8033:8033"
    environment:
      - NODE_TYPE=resourcemanager
    volumes:
      - ./config/resourcemanager:/home/hadoop/hadoop/etc/hadoop
      - ./scripts:/home/hadoop/scripts
    networks:
      - spark-hadoop-network
    command: ["/bin/bash","-lc","sed -i 's/\\r$//' /home/hadoop/scripts/*.sh && chmod +x /home/hadoop/scripts/*.sh && exec /home/hadoop/scripts/start-resourcemanager.sh"]

  nodemanager1:
    image: hadoop-multi:latest
    container_name: nodemanager1
    hostname: nodemanager1
    depends_on:
      - resourcemanager
      - datanode1
    ports:
      - "8042:8042"
    environment:
      - NODE_TYPE=nodemanager
      - RESOURCEMANAGER_HOST=resourcemanager
    volumes:
      - ./config/nodemanager:/home/hadoop/hadoop/etc/hadoop
      - ./scripts:/home/hadoop/scripts
    networks:
      - spark-hadoop-network
    command: ["/bin/bash","-lc","sed -i 's/\\r$//' /home/hadoop/scripts/*.sh && chmod +x /home/hadoop/scripts/*.sh && exec /home/hadoop/scripts/start-nodemanager.sh"]

  nodemanager2:
    image: hadoop-multi:latest
    container_name: nodemanager2
    hostname: nodemanager2
    depends_on:
      - resourcemanager
      - datanode2
    ports:
      - "8043:8042"
    environment:
      - NODE_TYPE=nodemanager
      - RESOURCEMANAGER_HOST=resourcemanager
    volumes:
      - ./config/nodemanager:/home/hadoop/hadoop/etc/hadoop
      - ./scripts:/home/hadoop/scripts
    networks:
      - spark-hadoop-network
    command: ["/bin/bash","-lc","sed -i 's/\\r$//' /home/hadoop/scripts/*.sh && chmod +x /home/hadoop/scripts/*.sh && exec /home/hadoop/scripts/start-nodemanager.sh"]

volumes:
  namenode_data:
  datanode1_data:
  datanode2_data:

networks:
  spark-hadoop-network:
    driver: bridge
    name: spark-hadoop-network