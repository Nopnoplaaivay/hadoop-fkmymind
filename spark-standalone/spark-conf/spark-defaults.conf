# ========== spark-conf/spark-defaults.conf ==========
spark.master                      spark://spark-master:7077
spark.eventLog.enabled            true
spark.eventLog.compress           true
spark.eventLog.dir                hdfs://namenode:9000/spark-logs
spark.history.fs.logDirectory     hdfs://namenode:9000/spark-logs
spark.serializer                  org.apache.spark.serializer.KryoSerializer
spark.driver.memory               2g
spark.executor.memory             2g
spark.executor.cores              2
spark.eventLog.overwrite          true
spark.sql.warehouse.dir           file:///home/spark/spark-warehouse
spark.driver.bindAddress          0.0.0.0
spark.driver.host                 jupyter-pyspark
spark.io.compression.codec        snappy

# Hadoop Configuration
spark.hadoop.fs.defaultFS         hdfs://namenode:9000
# spark.hadoop.yarn.resourcemanager.hostname   resourcemanager
# spark.hadoop.yarn.resourcemanager.address    resourcemanager:8032
# spark.hadoop.yarn.resourcemanager.webapp.address resourcemanager:8088
# spark.hadoop.mapreduce.framework.name        yarn
# spark.hadoop.yarn.app.mapreduce.am.env       HADOOP_MAPRED_HOME=/home/spark/hadoop
# spark.hadoop.mapreduce.map.env               HADOOP_MAPRED_HOME=/home/spark/hadoop
# spark.hadoop.mapreduce.reduce.env            HADOOP_MAPRED_HOME=/home/spark/hadoop

# HDFS client configuration
spark.hadoop.dfs.client.use.datanode.hostname false
spark.hadoop.dfs.replication      2

# Performance tuning
spark.sql.adaptive.enabled        true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.skewJoin.enabled          true
spark.sql.adaptive.localShuffleReader.enabled true
